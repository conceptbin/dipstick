{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dipstick.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "D7nlh4KlZWZL",
        "CGE1t_kFpSLw"
      ],
      "toc_visible": true,
      "mount_file_id": "1Joer3O59wPBZuS9Tyu6oVxdc_bDvdMDF",
      "authorship_tag": "ABX9TyP6wI/k6duRFX6DOJDAihMf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/conceptbin/dipstick/blob/master/Dipstick_0_2_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7nlh4KlZWZL",
        "colab_type": "text"
      },
      "source": [
        "#User input\n",
        "1. Enter search term and the limit (max. no. of tweets) in this section.\n",
        "2. Mount Google Drive for this notebook.\n",
        "3. Run all cells (Runtime > Run all)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibzEvEhHZnh2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "search_term = \"Roehampton\" #Enter search term here.\n",
        "limit = 5000 #If you're just testing the search, set a smaller limit."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRbUeUoe2DgG",
        "colab_type": "text"
      },
      "source": [
        "Below this cell, no editing is needed if you're just running the notebook as normal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFiFYTLMZWCR",
        "colab_type": "text"
      },
      "source": [
        "#Search and save to pandas dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdLrLf_jWZfO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Install Twint for Twitter search\n",
        "!pip3 install twint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "un-oeOpmB3l7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import twint\n",
        "\n",
        "c = twint.Config()\n",
        "c.Search = search_term\n",
        "c.Limit = limit\n",
        "#c.Min_likes = 5 #Minimum number of likes, to just get tweets people interacted with.\n",
        "c.Pandas = True\n",
        "\n",
        "twint.run.Search(c)\n",
        "df = twint.storage.panda.Tweets_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INm7MZL2YH5-",
        "colab_type": "text"
      },
      "source": [
        "#Basic Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1prG8lbdRxK-",
        "colab_type": "text"
      },
      "source": [
        "##User by frequency"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6vrSALdRwVX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "most_tweets = df.groupby(['username']).size().reset_index(name='counts')\n",
        "most_tweets = most_tweets.sort_values(by='counts', ascending=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNGS7lXDPjTl",
        "colab_type": "text"
      },
      "source": [
        "##Likes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jfImp7OMOlna",
        "colab": {}
      },
      "source": [
        "#Most likes\n",
        "most_l = (df.nlargest(1000, 'nlikes') \n",
        "          .drop_duplicates(['tweet'])\n",
        "          )\n",
        "most_l = most_l.sort_values(by='nlikes', ascending=False)[:100]\n",
        "#most_l[:10][['date','username','tweet','nlikes']]  #Show most liked"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXWdh1mYPf3-",
        "colab_type": "text"
      },
      "source": [
        "##Retweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtkLLz_zNOgf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Most retweeted\n",
        "most_r = (df.nlargest(1000, 'nretweets') \n",
        "          .drop_duplicates(['tweet'])\n",
        "          )\n",
        "most_r = most_r.sort_values(by='nretweets', ascending=False)[:100]\n",
        "#most_r[:10][['date','username','tweet','nretweets']]  #Uncomment this line to show most retweeted"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLDEBnlwNUXC",
        "colab_type": "text"
      },
      "source": [
        "##Overview"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fM_Jal5wu7pj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Overview data\n",
        "tweets_total = len(df)  #Total no. of tweets in the set\n",
        "tweeters = len(df['username'].unique())  #No. of unique tweeters\n",
        "median_likes = df['nlikes'].median() #Median number of likes\n",
        "median_retweets = df['nretweets'].median()  #Median number of retweets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rdFvCIlKlOu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Gather overview data into a dict\n",
        "report = {'What': ['Total no. of tweets in the sample', 'No. of unique tweeters', 'Median likes','Median retweets'],\n",
        "          'Number': [tweets_total, tweeters, median_likes, median_retweets]}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86_EgSAXLkgg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Make overview dataframe from dict and display\n",
        "report_table = pd.DataFrame(report)\n",
        "#report_table"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7ImZ7AV_s2e",
        "colab_type": "text"
      },
      "source": [
        "#Keywords, hashtags, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktkiI7j-BFZl",
        "colab_type": "text"
      },
      "source": [
        "##N-grams\n",
        "Code adapted from De Dios, From Dataframe to N-Grams (Medium 22 May 2020) [link text](https://towardsdatascience.com/from-dataframe-to-n-grams-e34e29df3460)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-wdXcDjBfwT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import libraries \n",
        "\n",
        "# natural language processing: n-gram ranking\n",
        "import re\n",
        "import unicodedata\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords\n",
        "# add appropriate words that will be ignored in the analysis\n",
        "#ADDITIONAL_STOPWORDS = ['covfefe']\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmDK5Z57BgGv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function for basic cleaning of the text.\n",
        "def basic_clean(text):\n",
        "  \"\"\"\n",
        "  A simple function to clean up the data. All the words that\n",
        "  are not designated as a stop word are lemmatized after\n",
        "  encoding and basic regex parsing are performed.\n",
        "  \"\"\"\n",
        "  wnl = nltk.stem.WordNetLemmatizer()\n",
        "  stopwords = nltk.corpus.stopwords.words('english') # + ADDITIONAL_STOPWORDS\n",
        "  text = (unicodedata.normalize('NFKD', text)\n",
        "    .encode('ascii', 'ignore')\n",
        "    .decode('utf-8', 'ignore')\n",
        "    .lower())\n",
        "  words = re.sub(r'[^\\w\\s]', '', text).split()\n",
        "  return [wnl.lemmatize(word) for word in words if word not in stopwords]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzYIaP8VB1Px",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#try out basic_clean\n",
        "words = basic_clean(''.join(str(df['tweet'].tolist())))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxJb2pSWB041",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Top 10 bigrams\n",
        "%%capture\n",
        "(pd.Series(nltk.ngrams(words, 2)).value_counts())[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vt89seykDKf8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#top 10 trigrams\n",
        "%%capture\n",
        "(pd.Series(nltk.ngrams(words, 3)).value_counts())[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2bczcDuDy4d",
        "colab_type": "text"
      },
      "source": [
        "##Visualization of N-grams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqY6ULmoDrzU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bigrams_series = (pd.Series(nltk.ngrams(words, 2)).value_counts())[:20]\n",
        "trigrams_series = (pd.Series(nltk.ngrams(words, 3)).value_counts())[:20]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73L_fY2tEcDe",
        "colab_type": "text"
      },
      "source": [
        "###Bigrams and Trigrams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDv-jsWcD2nA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Bigrams chart\n",
        "bigrams_series.sort_values().plot.barh(color='blue', width=.9, figsize=(12, 8))\n",
        "plt.title('20 Most Frequently Occuring Bigrams')\n",
        "plt.ylabel('Bigram')\n",
        "plt.xlabel('# of Occurences')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkDBc_EAEKY4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Trigrams chart\n",
        "trigrams_series.sort_values().plot.barh(color='blue', width=.9, figsize=(12, 8))\n",
        "plt.title('20 Most Frequently Occuring Trigrams')\n",
        "plt.ylabel('Trigram')\n",
        "plt.xlabel('# of Occurences')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iApBWCaAaTjO",
        "colab_type": "text"
      },
      "source": [
        "##Hashtags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIJq61SDaQ30",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function for cleaning the hashtags column and collecting into a list.\n",
        "def tag_clean(text):\n",
        "  \"\"\"\n",
        "  Simplified version of the basic_clean function. This returns a list of hashtags.\n",
        "  \"\"\"\n",
        "  wnl = nltk.stem.WordNetLemmatizer()\n",
        "  text = (unicodedata.normalize('NFKD', text)\n",
        "    .encode('ascii', 'ignore')\n",
        "    .decode('utf-8', 'ignore')\n",
        "    .lower())\n",
        "  words = re.sub(r'[^\\w\\s]', '', text).split()\n",
        "  return [wnl.lemmatize(word) for word in words]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_dz_UvuyYDL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Assemble tag_clean output into list\n",
        "tags = tag_clean(''.join(str(df['hashtags'].tolist())))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgipwTnayqbn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Gather top hashtags\n",
        "hashtags_series = (pd.Series(tags).value_counts())[:30]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbmxh-7C1SQS",
        "colab_type": "text"
      },
      "source": [
        "###Visualization of top hashtags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RdJWYufu1QqF",
        "colab": {}
      },
      "source": [
        "#Show chart of top hashtags\n",
        "hashtags_series.sort_values().plot.barh(color='blue', width=.9, figsize=(12, 8))\n",
        "plt.title('30 Most Frequent Hashtags')\n",
        "plt.ylabel('Hashtag')\n",
        "plt.xlabel('# of Occurences')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGE1t_kFpSLw",
        "colab_type": "text"
      },
      "source": [
        "# Output\n",
        "The Excel sheet \"dipstick_out.xlsx\" can be found in your file folders sidebar on Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6olDd6VPZmq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Save dataframes to separate sheets in an Excel workbook.\n",
        "with pd.ExcelWriter('dipstick_out.xlsx') as writer:\n",
        "  report_table.to_excel(writer, sheet_name='Overview report')\n",
        "  most_l.to_excel(writer, sheet_name='Most likes')\n",
        "  most_r.to_excel(writer, sheet_name='Most retweets')\n",
        "  most_tweets.to_excel(writer, sheet_name='Most tweets by user')\n",
        "  bigrams_series.to_excel(writer, sheet_name='Top bigrams (stopwords removed')\n",
        "  trigrams_series.to_excel(writer, sheet_name='Top trigrams')\n",
        "  hashtags_series.to_excel(writer, sheet_name='Top hashtags')\n",
        "  df.to_excel(writer, sheet_name='All tweets')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
