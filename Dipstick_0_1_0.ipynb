{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dipstick 0.1.0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1HWYissTXp6LVxG4qfKfK3xJoEVKVO1sh",
      "authorship_tag": "ABX9TyMhtFEJFqmx5fDCFEGvd8yq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/conceptbin/dipstick/blob/master/Dipstick_0_1_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "142VL0nPWNpd",
        "colab_type": "text"
      },
      "source": [
        "#Dipstick for Twitter\n",
        "A simple search and analytics report. Enter your search term and how many tweets you want. Your report (including all the tweets in the dataset) will output to an Excel sheet. This will be saved in the folder where your notebook is located. This project is built on the broad shoulders of [Twint](https://github.com/twintproject/twint), [pandas](https://pandas.pydata.org/docs/index.html#) and [sklearn](https://scikit-learn.org/stable/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7nlh4KlZWZL",
        "colab_type": "text"
      },
      "source": [
        "1. Enter your search term and the maximum number of tweets you want collected:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibzEvEhHZnh2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "search_term = \"Pineapple\" #Enter search term here.\n",
        "limit = 1000 #Change this as you wish. If you're just testing the search, set a smaller limit."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U29NVA4KgtNJ",
        "colab_type": "text"
      },
      "source": [
        "2. In the Runtime-menu, select \"Run all\". Please be patient while the tweets trickle in."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFiFYTLMZWCR",
        "colab_type": "text"
      },
      "source": [
        "#Search and save to pandas dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdLrLf_jWZfO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Install Twint for Twitter search. (This is only necessary if you're using Google Colab)\n",
        "!pip3 install twint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "un-oeOpmB3l7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import twint\n",
        "\n",
        "c = twint.Config()\n",
        "c.Search = search_term\n",
        "c.Limit = limit\n",
        "#c.Min_likes = 5 #Minimum number of likes, to just get tweets people interacted with.\n",
        "c.Pandas = True\n",
        "\n",
        "twint.run.Search(c)\n",
        "df = twint.storage.panda.Tweets_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INm7MZL2YH5-",
        "colab_type": "text"
      },
      "source": [
        "#Basic Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1prG8lbdRxK-",
        "colab_type": "text"
      },
      "source": [
        "##User by frequency"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6vrSALdRwVX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "most_tweets = df.groupby(['username']).size().reset_index(name='counts')\n",
        "most_tweets = most_tweets.sort_values(by='counts', ascending=False)\n",
        "most_tweets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNGS7lXDPjTl",
        "colab_type": "text"
      },
      "source": [
        "##Likes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jfImp7OMOlna",
        "colab": {}
      },
      "source": [
        "#Most likes\n",
        "most_l = (df.nlargest(1000, 'nlikes') \n",
        "          .drop_duplicates(['tweet'])\n",
        "          )\n",
        "most_l = most_l.sort_values(by='nlikes', ascending=False)\n",
        "most_l[:10][['date','username','tweet','nlikes']]  #Slice of list, selected columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXWdh1mYPf3-",
        "colab_type": "text"
      },
      "source": [
        "##Retweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtkLLz_zNOgf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Most retweeted\n",
        "most_r = (df.nlargest(1000, 'nretweets') \n",
        "          .drop_duplicates(['tweet'])\n",
        "          )\n",
        "most_r[:10][['date','username','tweet','nretweets']]  #Slice of list, selected columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLDEBnlwNUXC",
        "colab_type": "text"
      },
      "source": [
        "##Overview"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fM_Jal5wu7pj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Overview data\n",
        "tweets_total = len(df)  #Total no. of tweets in the set\n",
        "tweeters = len(df['username'].unique())  #No. of unique tweeters\n",
        "median_likes = df['nlikes'].median() #Median number of likes\n",
        "median_retweets = df['nretweets'].median()  #Median number of retweets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rdFvCIlKlOu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Gather overview data into a dict\n",
        "report = {'What': ['Total no. of tweets in the sample', 'No. of unique tweeters', 'Median likes','Median retweets'],\n",
        "          'Number': [tweets_total, tweeters, median_likes, median_retweets]}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86_EgSAXLkgg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Make overview dataframe from dict and display\n",
        "report_table = pd.DataFrame(report)\n",
        "report_table"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7ImZ7AV_s2e",
        "colab_type": "text"
      },
      "source": [
        "#Keywords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egtYPuzxdPbz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrPJeoJuNF6F",
        "colab_type": "text"
      },
      "source": [
        "Code below adapted from Susan Li, \"A Complete Exploratory Data Analysis and Visualization for Text Data\" (Medium, 18 Mar 2019): https://towardsdatascience.com/a-complete-exploratory-data-analysis-and-visualization-for-text-data-29fb1b96fb6a"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdC1iDjy7mb5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(TweetText):\n",
        "    TweetText = TweetText.str.replace(\"(<br/>)\", \"\")\n",
        "    TweetText = TweetText.str.replace('(<a).*(>).*(</a>)', '')\n",
        "    TweetText = TweetText.str.replace('(&amp)', '')\n",
        "    TweetText = TweetText.str.replace('(&gt)', '')\n",
        "    TweetText = TweetText.str.replace('(&lt)', '')\n",
        "    TweetText = TweetText.str.replace('(\\xa0)', ' ')  \n",
        "    return TweetText\n",
        "df['tweet'] = preprocess(df['tweet'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZDJe1YhIWQX",
        "colab_type": "text"
      },
      "source": [
        "##Top unigrams before removing stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbeyBb6BFjFC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_top_n_words(corpus, n=None):\n",
        "    vec = CountVectorizer().fit(corpus)\n",
        "    bag_of_words = vec.transform(corpus)\n",
        "    sum_words = bag_of_words.sum(axis=0) \n",
        "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
        "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
        "    return words_freq[:n]\n",
        "common_words = get_top_n_words(df['tweet'], 20)\n",
        "#for word, freq in common_words:\n",
        "#    print(word, freq)\n",
        "df1 = pd.DataFrame(common_words, columns = ['tweet' , 'count'])\n",
        "#df1.groupby('tweet').sum()['count'].sort_values(ascending=False).iplot(\n",
        "#   kind='bar', yTitle='Count', linecolor='black', title='Top 20 words in review before removing stop words')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKa1G-omH1MT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-1eVKk_LmCJ",
        "colab_type": "text"
      },
      "source": [
        "##Top unigrams after removing stop words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlDGkUsYLKnh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_top_n_words(corpus, n=None):\n",
        "    vec = CountVectorizer(stop_words = 'english').fit(corpus)\n",
        "    bag_of_words = vec.transform(corpus)\n",
        "    sum_words = bag_of_words.sum(axis=0) \n",
        "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
        "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
        "    return words_freq[:n]\n",
        "common_words = get_top_n_words(df['tweet'], 30)\n",
        "#for word, freq in common_words:\n",
        "#    print(word, freq)\n",
        "df2 = pd.DataFrame(common_words, columns = ['tweet' , 'count'])\n",
        "df2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGE1t_kFpSLw",
        "colab_type": "text"
      },
      "source": [
        "# Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6olDd6VPZmq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Save dataframes to separate sheets in an Excel workbook.\n",
        "with pd.ExcelWriter('dipstick_out.xlsx') as writer:\n",
        "  report_table.to_excel(writer, sheet_name='Overview report')\n",
        "  most_l.to_excel(writer, sheet_name='Most likes')\n",
        "  most_r.to_excel(writer, sheet_name='Most retweets')\n",
        "  most_tweets.to_excel(writer, sheet_name='Most tweets by user')\n",
        "  df2.to_excel(writer, sheet_name='Top unigrams (stopwords removed')\n",
        "  df.to_excel(writer, sheet_name='All tweets')\n",
        "  \n",
        "  print(\"Done!\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
